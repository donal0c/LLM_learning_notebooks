{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe8355e-522a-479d-a3d8-b64df9699acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY', 'default_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f52e75-e978-4112-a441-a381476786d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c0053c-7c0f-4fd9-a109-38bd8211bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8de3cb-184d-4a7e-bbf3-37542596720f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33814ef-434d-47cc-809e-61b58f27d1c0",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145a7126-ef69-4c92-9e44-665b9a3ce5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop \\\n",
    "and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca4e4be-2744-4570-ac55-7c794065bb80",
   "metadata": {},
   "source": [
    "### Lollipop is 3 tokens (l - oll - ipop ) it finds it diffitcult to reverse each and in order( uncommon word 'things' is one ) \n",
    "### so splitting it into seperate tokens l-o-l-l-i-p-o-p makes it easier \n",
    "\n",
    "#### English on average 1 token is 4 characters or 3/4 of a word\n",
    "#### There are limits on the tokens for input `context` and output completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8605b890-915e-488c-8d93-206ea3b1a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de40bdc6-a91d-46d8-a037-6abeef7d2e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p-o-p-i-l-l-o-l'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3516d-23ed-444d-9ea4-3d2e5c6258f3",
   "metadata": {},
   "source": [
    "## System, User and assistant Messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfffc9a-99cc-4cca-a432-521d59b3eff1",
   "metadata": {},
   "source": [
    "### Helper function (Chat Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99bd3b94-9d61-4c5d-bd68-32a40a1c99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, \n",
    "                                 model=\"gpt-3.5-turbo\", \n",
    "                                 temperature=0, \n",
    "                                 max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens, # the maximum number of tokens the model can ouptut \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05827b34-37cd-49e2-9927-5634c4b71380",
   "metadata": {},
   "source": [
    "#### The 'assistant' role would be used to pass the previous respones to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6de98b70-66a2-4411-aff1-13fb42171247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a carrot, oh so bright,\n",
      "With skin so orange, like the sun's delight.\n",
      "It grew with joy, in soil so fine,\n",
      "A cheerful carrot, always in a line.\n",
      "\n",
      "It danced with glee, in the gentle breeze,\n",
      "With leafy greens swaying, like a party, please!\n",
      "The carrot giggled, full of sweet surprise,\n",
      "As it soaked up sunshine from the skies.\n",
      "\n",
      "Oh, this happy carrot, so full of mirth,\n",
      "Bringing smiles to all, a source of worth.\n",
      "With every crunch, a burst of delight,\n",
      "A tasty treat, now out of sight.\n",
      "\n",
      "So remember, my friend, the tale of this carrot,\n",
      "A little root vegetable, singing like a parrot.\n",
      "Cherish the joy, in all that you do,\n",
      "And let your happiness shine through and through!\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who\\\n",
    " responds in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user', \n",
    " 'content':\"\"\"write me a very short poem\\\n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d89f3c-eeff-4889-b101-9eec19dd5a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a happy carrot named Carrotopus who lived in a vibrant vegetable garden and delighted in bringing joy to others.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':'All your responses must be \\\n",
    "one sentence long.'},    \n",
    "{'role':'user',\n",
    " 'content':'write me a story about a happy carrot'},  \n",
    "] \n",
    "response = get_completion_from_messages(messages, temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52456417-8165-4924-ad1a-e804a1b3b1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a carrot so bright and so cheery, it hopped around fields all day, never weary.\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages =  [  \n",
    "{'role':'system',\n",
    " 'content':\"\"\"You are an assistant who \\\n",
    "responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a story about a happy carrot\"\"\"},\n",
    "] \n",
    "response = get_completion_from_messages(messages, \n",
    "                                        temperature =1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78a1e5-0d60-4937-8032-1ee2f8153916",
   "metadata": {},
   "source": [
    "### Helper function to get completion and the Token count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c861a30-a184-4c5c-a71f-9eb6e9db6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(messages, \n",
    "                                   model=\"gpt-3.5-turbo\", \n",
    "                                   temperature=0, \n",
    "                                   max_tokens=500):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message[\"content\"]\n",
    "    \n",
    "    token_dict = {\n",
    "'prompt_tokens':response['usage']['prompt_tokens'],\n",
    "'completion_tokens':response['usage']['completion_tokens'],\n",
    "'total_tokens':response['usage']['total_tokens'],\n",
    "    }\n",
    "\n",
    "    return content, token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19fc9ad4-fd7d-4c16-b110-4fde0e19435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "{'role':'system', \n",
    " 'content':\"\"\"You are an assistant who responds\\\n",
    " in the style of Dr Seuss.\"\"\"},    \n",
    "{'role':'user',\n",
    " 'content':\"\"\"write me a very short poem \\ \n",
    " about a happy carrot\"\"\"},  \n",
    "] \n",
    "response, token_dict = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af5ca005-ca7b-4d7c-b2f0-9eda8c712d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "Grown in the garden, a joyful forage.\n",
      "With a smile so wide, from top to bottom,\n",
      "It brings happiness, oh how it blossoms!\n",
      "\n",
      "In the soil it grew, with love and care,\n",
      "Nourished by sunshine, fresh air to share.\n",
      "Its leaves so green, reaching up so high,\n",
      "A happy carrot, oh my, oh my!\n",
      "\n",
      "With a crunch and a munch, it's oh so tasty,\n",
      "Filled with vitamins, oh so hasty.\n",
      "A happy carrot, a delight to eat,\n",
      "Bringing joy and health, oh what a treat!\n",
      "\n",
      "So let's celebrate this veggie so grand,\n",
      "With a happy carrot in each hand.\n",
      "For in its presence, we surely find,\n",
      "A taste of happiness, one of a kind!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6cb0081-3909-4a64-a289-9ebcc0330b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 37, 'completion_tokens': 164, 'total_tokens': 201}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5eb84-59e6-4863-89b1-1260f4a6f3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
